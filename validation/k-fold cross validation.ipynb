{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_data = pd.read_csv(\"hate_speech_binary_dataset.csv\", delimiter=\",\") # 혐오 문장\n",
    "genderbias_data = pd.read_csv('genderbias.csv', sep=',')  # 여성 비하 문장\n",
    "ilbe_data = pd.read_csv('badword.csv',encoding='CP949') # 일베 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혐오 문장 처리\n",
    "hate_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "hate_data = hate_data.astype({'comment': 'str'})\n",
    "hate_data = hate_data[hate_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여성 비하 문장 처리\n",
    "del genderbias_data['bias']    #해당 데이터셋의 필요없는 열 제거\n",
    "del genderbias_data['hate']    #해당 데이터셋의 필요없는 열 제거\n",
    "genderbias_data['contain_gender_bias'] = genderbias_data['contain_gender_bias'].replace([False, True],[0,1])  # 구분하기 쉽게 기존의 표기를 0,1로 변경\n",
    "# genderbias_data = genderbias_data[['contain_gender_bias', 'comments']]    #구분하기 쉽게 열의 순서를 변경\n",
    "\n",
    "genderbias_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "genderbias_data = genderbias_data[genderbias_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일베 문장 처리\n",
    "ilbe_data = ilbe_data[['v2', 'v1']]    #구분하기 쉽게 열의 순서를 변경\n",
    "ilbe_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "ilbe_data = ilbe_data[ilbe_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_data : 100000\n",
      "genderbias_data : 1232\n",
      "ilbe_data : 2044\n"
     ]
    }
   ],
   "source": [
    "# 데이터 개수\n",
    "print(\"hate_data : %d\" % len(hate_data))\n",
    "print(\"genderbias_data : %d\" % len(genderbias_data))\n",
    "print(\"ilbe_data : %d\" % len(ilbe_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라벨링 및 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 렌덤하게 문장 추출 후 라벨링 거치는 함수\n",
    "def random_labeling(data, classified_data, label_num, str_num):  # label_num : 라벨링 시킬 값, str_num 추출할 문장 개수\n",
    "    random_data = classified_data.sample(n=str_num) # str_num 개의 행(문장) 랜덤 추출\n",
    "    random_data.loc[random_data.label == 1, 'label'] = label_num # label_num으로 값 변경\n",
    "    data = data.append(random_data)  # data 에 랜덤 추출된 데이터 추가\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>str_Declaration</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           comment  label\n",
       "0  str_Declaration     -1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_declaration = {\n",
    "    'comment' : [\"str_Declaration\"],\n",
    "    'label':[-1]\n",
    "}\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data_declaration)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 개수를 모두 2000 개로 지정 각 \n",
    "# 라벨은 혐오:0, 여성비하: 1, 일베: 2로 지정됨\n",
    "data = random_labeling(data, hate_data, 0, 2000)\n",
    "data = random_labeling(data, genderbias_data, 1, 1200)\n",
    "data = random_labeling(data, ilbe_data, 2, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 첫번째 행 제거\n",
    "data = data.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 랜덤하게 섞기 \n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저 새끼 파보면</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>목사한테 빤쓰내림!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너무 재밌어요~~^^ 미스터빈 연기 굿굿굿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>양육비로 생계 유지하면서 나이트에서 남자 데려와서 떡침</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>남자들이 불쌍하다 미투니뭐니 나라가 미쳤구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>난 너무 재밌게봤다... 특히 흉흉한 요즘세상에당사자의 고통과 가장 약했던 여자의 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>말이 필요없ㄷㅏ ㅠ ㅠ 한 5번넘게 본 듯</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>이런 영화가 많아져야 한다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25년전이면 한참 팔팔할때.. 오달수도 아마 이십대 초반.. 서로 어렸을때 반콩깠던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>실제로 김대중이라고 했는데 김재중이라고 한거라고 구라친거라는 생각은 안해봣노 ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label\n",
       "0                                           저 새끼 파보면      2\n",
       "1                                         목사한테 빤쓰내림!      2\n",
       "2                            너무 재밌어요~~^^ 미스터빈 연기 굿굿굿      0\n",
       "3                     양육비로 생계 유지하면서 나이트에서 남자 데려와서 떡침      2\n",
       "4                           남자들이 불쌍하다 미투니뭐니 나라가 미쳤구나      1\n",
       "5  난 너무 재밌게봤다... 특히 흉흉한 요즘세상에당사자의 고통과 가장 약했던 여자의 ...      0\n",
       "6                            말이 필요없ㄷㅏ ㅠ ㅠ 한 5번넘게 본 듯      0\n",
       "7                                    이런 영화가 많아져야 한다.      0\n",
       "8  25년전이면 한참 팔팔할때.. 오달수도 아마 이십대 초반.. 서로 어렸을때 반콩깠던...      1\n",
       "9       실제로 김대중이라고 했는데 김재중이라고 한거라고 구라친거라는 생각은 안해봣노 ?      2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복 및 null 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_overlap(data):\n",
    "    exist_overlap = len(data)  # 데이터 전체 개수\n",
    "    no_overlap = data['comment'].nunique()  # 중복 제거된 개수\n",
    "    if exist_overlap != no_overlap:\n",
    "        data.drop_duplicates(subset=['comment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_overlap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null 값 확인\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x_data, tokenizer):\n",
    "    tokenizer.fit_on_texts(x_data) # 데이터의 각 행별로 토큰화 수행\n",
    "    return tokenizer.texts_to_sequences(x_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data['comment']\n",
    "y_data = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "sequences = tokenize(x_data, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 희귀단어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rareword(tokenizer, threshold):\n",
    "    word_to_index = tokenizer.word_index \n",
    "    total_cnt = len(word_to_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등장 빈도가 1번 이하인 희귀 단어의 수: 23592\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 83.37279570272467\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 49.086596479547254\n"
     ]
    }
   ],
   "source": [
    "# 희귀 단어 확인\n",
    "detect_rareword(tokenizer, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터, 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 길이\n",
    "def max_length(X_data):\n",
    "    return max(len(l) for l in X_data)\n",
    "\n",
    "# 훈련 학습 데이터 개수\n",
    "def num_dataset(raio, X_data):\n",
    "    num_train = int(len(X_data)*0.8)\n",
    "    num_test = int(len(X_data) - num_train)\n",
    "    return num_train, num_test\n",
    "\n",
    "Y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이 계산\n",
    "X_data = sequences\n",
    "maxlen = max_length(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터, 학습 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 학습 데이터 개수 비율 지정\n",
    "numtrain, numtest = num_dataset(0.8, X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 길이로 맞추기\n",
    "X_data = pad_sequences(X_data, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    25,   219,  4706],\n",
       "       [    0,     0,     0, ...,     0,  4707,  4708],\n",
       "       [    0,     0,     0, ...,  2273,    53,  4709],\n",
       "       ...,\n",
       "       [    0,     0,     0, ..., 28289, 28290,  2215],\n",
       "       [    0,     0,     0, ..., 28296, 28297,  1433],\n",
       "       [    0,     0,     0, ...,    65,  1526,    65]], dtype=int32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import tensorflow.keras.metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "325/325 [==============================] - 180s 550ms/step - loss: 1.0857 - acc: 0.3854 - f1_m: 3.1065 - precision_m: 116596976.2699 - recall_m: 1.5979\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 187s 575ms/step - loss: 1.0600 - acc: 0.4258 - f1_m: 2.8453 - precision_m: 100664662.0000 - recall_m: 1.4780\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 185s 568ms/step - loss: 0.8568 - acc: 0.6049 - f1_m: 1.7152 - precision_m: 2.5086 - recall_m: 1.4537\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 184s 565ms/step - loss: 0.5682 - acc: 0.7611 - f1_m: 1.1435 - precision_m: 1.0237 - recall_m: 1.3448\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 181s 557ms/step - loss: 0.3416 - acc: 0.8707 - f1_m: 0.9084 - precision_m: 0.7481 - recall_m: 1.1887\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 173s 533ms/step - loss: 0.2006 - acc: 0.9438 - f1_m: 0.8137 - precision_m: 0.6660 - recall_m: 1.0746\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 173s 533ms/step - loss: 0.1263 - acc: 0.9655 - f1_m: 0.7989 - precision_m: 0.6585 - recall_m: 1.0385\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 173s 533ms/step - loss: 0.0876 - acc: 0.9780 - f1_m: 0.7672 - precision_m: 0.6251 - recall_m: 1.0193\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 184s 565ms/step - loss: 0.0609 - acc: 0.9841 - f1_m: 0.7675 - precision_m: 0.6267 - recall_m: 1.0113\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 189s 582ms/step - loss: 0.0467 - acc: 0.9882 - f1_m: 0.7548 - precision_m: 0.6154 - recall_m: 1.0044\n",
      "Epoch 1/10\n",
      "325/325 [==============================] - 189s 579ms/step - loss: 1.0884 - acc: 0.3883 - f1_m: 3.0183 - precision_m: 89893015.7165 - recall_m: 1.6003\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 193s 593ms/step - loss: 1.0681 - acc: 0.4087 - f1_m: 3.0101 - precision_m: 113939290.2117 - recall_m: 1.5474\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 189s 583ms/step - loss: 0.9081 - acc: 0.5602 - f1_m: 1.8878 - precision_m: 3.4920 - recall_m: 1.4848\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 187s 574ms/step - loss: 0.5980 - acc: 0.7248 - f1_m: 1.2000 - precision_m: 1.0734 - recall_m: 1.4078\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 186s 572ms/step - loss: 0.4572 - acc: 0.7978 - f1_m: 1.0362 - precision_m: 0.8871 - recall_m: 1.2866\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 183s 562ms/step - loss: 0.3028 - acc: 0.8880 - f1_m: 0.8934 - precision_m: 0.7428 - recall_m: 1.1497\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 184s 566ms/step - loss: 0.1858 - acc: 0.9430 - f1_m: 0.8038 - precision_m: 0.6580 - recall_m: 1.0604\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 181s 556ms/step - loss: 0.1129 - acc: 0.9660 - f1_m: 0.7858 - precision_m: 0.6455 - recall_m: 1.0310\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 181s 557ms/step - loss: 0.0812 - acc: 0.9719 - f1_m: 0.7765 - precision_m: 0.6338 - recall_m: 1.0236\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 183s 564ms/step - loss: 0.0512 - acc: 0.9860 - f1_m: 0.7570 - precision_m: 0.6130 - recall_m: 1.0132\n",
      "Epoch 1/10\n",
      "325/325 [==============================] - 182s 557ms/step - loss: 1.0952 - acc: 0.3720 - f1_m: 3.0794 - precision_m: 106279546.8957 - recall_m: 1.5925\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 181s 557ms/step - loss: 1.0763 - acc: 0.3930 - f1_m: 2.9945 - precision_m: 129197822.1994 - recall_m: 1.5204\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 179s 552ms/step - loss: 0.9153 - acc: 0.5553 - f1_m: 1.9968 - precision_m: 5218520.8743 - recall_m: 1.4746\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 182s 560ms/step - loss: 0.5971 - acc: 0.7304 - f1_m: 1.2651 - precision_m: 1.1442 - recall_m: 1.4736\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 185s 568ms/step - loss: 0.4039 - acc: 0.8491 - f1_m: 1.0119 - precision_m: 0.8533 - recall_m: 1.2739\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 181s 556ms/step - loss: 0.2202 - acc: 0.9287 - f1_m: 0.8420 - precision_m: 0.6911 - recall_m: 1.1137\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 180s 554ms/step - loss: 0.1152 - acc: 0.9694 - f1_m: 0.7854 - precision_m: 0.6424 - recall_m: 1.0403\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 180s 555ms/step - loss: 0.0751 - acc: 0.9815 - f1_m: 0.7839 - precision_m: 0.6432 - recall_m: 1.0248\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 183s 563ms/step - loss: 0.0505 - acc: 0.9875 - f1_m: 0.7602 - precision_m: 0.6193 - recall_m: 1.0070\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 179s 549ms/step - loss: 0.0329 - acc: 0.9921 - f1_m: 0.7603 - precision_m: 0.6184 - recall_m: 1.0085\n",
      "Epoch 1/10\n",
      "325/325 [==============================] - 163s 500ms/step - loss: 1.0966 - acc: 0.3596 - f1_m: 3.3276 - precision_m: 154365193.6258 - recall_m: 1.6777\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 163s 501ms/step - loss: 1.0570 - acc: 0.4345 - f1_m: 2.8563 - precision_m: 94518204.2408 - recall_m: 1.5035\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 162s 500ms/step - loss: 0.7988 - acc: 0.6239 - f1_m: 1.5329 - precision_m: 1.7436 - recall_m: 1.4792\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 162s 499ms/step - loss: 0.5723 - acc: 0.7263 - f1_m: 1.2624 - precision_m: 1.0955 - recall_m: 1.5334\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 162s 499ms/step - loss: 0.4883 - acc: 0.7539 - f1_m: 1.1412 - precision_m: 0.9570 - recall_m: 1.4536\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 162s 498ms/step - loss: 0.3677 - acc: 0.8372 - f1_m: 1.0056 - precision_m: 0.8411 - recall_m: 1.2906\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 162s 498ms/step - loss: 0.2654 - acc: 0.9083 - f1_m: 0.8612 - precision_m: 0.7058 - recall_m: 1.1278\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 162s 498ms/step - loss: 0.1859 - acc: 0.9429 - f1_m: 0.8019 - precision_m: 0.6566 - recall_m: 1.0522\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 164s 504ms/step - loss: 0.1265 - acc: 0.9653 - f1_m: 0.7749 - precision_m: 0.6317 - recall_m: 1.0315\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 164s 506ms/step - loss: 0.0860 - acc: 0.9759 - f1_m: 0.7607 - precision_m: 0.6152 - recall_m: 1.0249\n",
      "Epoch 1/10\n",
      "325/325 [==============================] - 170s 520ms/step - loss: 1.0924 - acc: 0.3764 - f1_m: 3.1428 - precision_m: 112095885.2434 - recall_m: 1.6352\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 168s 518ms/step - loss: 1.0609 - acc: 0.4231 - f1_m: 3.0083 - precision_m: 106832129.8528 - recall_m: 1.5549\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 168s 517ms/step - loss: 0.8827 - acc: 0.5680 - f1_m: 1.8614 - precision_m: 3.5551 - recall_m: 1.4668\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 168s 518ms/step - loss: 0.5575 - acc: 0.7684 - f1_m: 1.1701 - precision_m: 1.0366 - recall_m: 1.3942\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 168s 517ms/step - loss: 0.3614 - acc: 0.8724 - f1_m: 0.9279 - precision_m: 0.7610 - recall_m: 1.2151\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 168s 517ms/step - loss: 0.2060 - acc: 0.9293 - f1_m: 0.8264 - precision_m: 0.6743 - recall_m: 1.0932\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 167s 514ms/step - loss: 0.1153 - acc: 0.9725 - f1_m: 0.7945 - precision_m: 0.6499 - recall_m: 1.0487\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 167s 515ms/step - loss: 0.0788 - acc: 0.9801 - f1_m: 0.7709 - precision_m: 0.6265 - recall_m: 1.0266\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 168s 516ms/step - loss: 0.0507 - acc: 0.9836 - f1_m: 0.7588 - precision_m: 0.6161 - recall_m: 1.0156\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 168s 515ms/step - loss: 0.0305 - acc: 0.9939 - f1_m: 0.7629 - precision_m: 0.6234 - recall_m: 1.0102\n"
     ]
    }
   ],
   "source": [
    "size = 1000000\n",
    "\n",
    "kfold = KFold(n_splits= 5, shuffle = True)\n",
    "\n",
    "for train, test in kfold.split(X_data, Y_data):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(size , 64, input_length = maxlen)) #워드 임베딩\n",
    "    model.add(Dropout(0.6)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "    model.add(Conv1D(64, 3, padding='valid', activation='relu')) #hidden layer 추가\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.6)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.6)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "    num_of_class = 3 #클래스는 우선 4개로 분류함\n",
    "    model.add(Dense(num_of_class, activation='softmax')) #마지막 레이어는 softmax로 출력하게 함\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    es = EarlyStopping(monitor='loss', mode='min' , min_delta=0)\n",
    "    check_point = ModelCheckpoint('best_model.h5', monitor='loss', mode='min', save_best_only=True)\n",
    "    \n",
    "    hist = model.fit(X_data, y_data, batch_size = 16, epochs=10, callbacks=[es, check_point])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "260/260 [==============================] - 127s 489ms/step - loss: 1.0904 - accuracy: 0.3751\n",
      "Epoch 2/10\n",
      "260/260 [==============================] - 129s 494ms/step - loss: 1.0737 - accuracy: 0.3922\n",
      "Epoch 3/10\n",
      "260/260 [==============================] - 130s 501ms/step - loss: 1.0205 - accuracy: 0.4742\n",
      "Epoch 4/10\n",
      "260/260 [==============================] - 131s 505ms/step - loss: 0.6973 - accuracy: 0.7045\n",
      "Epoch 5/10\n",
      "260/260 [==============================] - 133s 511ms/step - loss: 0.4449 - accuracy: 0.8346\n",
      "Epoch 6/10\n",
      "260/260 [==============================] - 132s 508ms/step - loss: 0.2696 - accuracy: 0.9127\n",
      "Epoch 7/10\n",
      "260/260 [==============================] - 133s 512ms/step - loss: 0.1363 - accuracy: 0.9605\n",
      "Epoch 8/10\n",
      "260/260 [==============================] - 132s 506ms/step - loss: 0.0865 - accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "260/260 [==============================] - 132s 509ms/step - loss: 0.0745 - accuracy: 0.9817\n",
      "Epoch 10/10\n",
      "260/260 [==============================] - 135s 519ms/step - loss: 0.0411 - accuracy: 0.9902\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size = 16, epochs=10, callbacks=[es, check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-5f13e7674d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0macc_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#모델 학습 과정 표시\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(model.predict(X_test, batch_size=16),columns=['0', '1', '2'])\n",
    "result[\"Test Label\"] = y_test\n",
    "\n",
    "result.to_csv(\"test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_data, Y_data, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(model.predict(X_data, batch_size=16),columns=['0', '1', '2'])\n",
    "result[\"Test Label\"] = Y_data\n",
    "\n",
    "result.to_csv(\"test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 2ms/step - loss: 0.8953 - accuracy: 0.7341\n",
      "테스트 정확도: 0.7341\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "##모델을 .json 파일 형식으로 save하여 저장\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"model_weight.h5\")\n",
    "model.save('full_model.h5')\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "##모델 조정이 아직 끝나지 않았습니다. 테스트 정확도를 더 늘리기 위해서 모델을 추가로 수정할 예정입니다,\n",
    "##모델 조정이 끝나면, Model을 사용 하여 OpenMax에 필요한 자료를 선정하여 OpenMax로 구현할 예정입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
