{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_data = pd.read_csv(\"hate_speech_binary_dataset.csv\", delimiter=\",\") # 혐오 문장\n",
    "genderbias_data = pd.read_csv('genderbias.csv', sep=',')  # 여성 비하 문장\n",
    "ilbe_data = pd.read_csv('badword.csv',encoding='CP949') # 일베 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혐오 문장 처리\n",
    "hate_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "hate_data = hate_data.astype({'comment': 'str'})\n",
    "hate_data = hate_data[hate_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여성 비하 문장 처리\n",
    "del genderbias_data['bias']    #해당 데이터셋의 필요없는 열 제거\n",
    "del genderbias_data['hate']    #해당 데이터셋의 필요없는 열 제거\n",
    "genderbias_data['contain_gender_bias'] = genderbias_data['contain_gender_bias'].replace([False, True],[0,1])  # 구분하기 쉽게 기존의 표기를 0,1로 변경\n",
    "# genderbias_data = genderbias_data[['contain_gender_bias', 'comments']]    #구분하기 쉽게 열의 순서를 변경\n",
    "\n",
    "genderbias_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "genderbias_data = genderbias_data[genderbias_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일베 문장 처리\n",
    "ilbe_data = ilbe_data[['v2', 'v1']]    #구분하기 쉽게 열의 순서를 변경\n",
    "ilbe_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "ilbe_data = ilbe_data[ilbe_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_data : 100000\n",
      "genderbias_data : 1232\n",
      "ilbe_data : 2044\n"
     ]
    }
   ],
   "source": [
    "# 데이터 개수\n",
    "print(\"hate_data : %d\" % len(hate_data))\n",
    "print(\"genderbias_data : %d\" % len(genderbias_data))\n",
    "print(\"ilbe_data : %d\" % len(ilbe_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라벨링 및 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 렌덤하게 문장 추출 후 라벨링 거치는 함수\n",
    "def random_labeling(data, classified_data, label_num, str_num):  # label_num : 라벨링 시킬 값, str_num 추출할 문장 개수\n",
    "    random_data = classified_data.sample(n=str_num) # str_num 개의 행(문장) 랜덤 추출\n",
    "    random_data.loc[random_data.label == 1, 'label'] = label_num # label_num으로 값 변경\n",
    "    data = data.append(random_data)  # data 에 랜덤 추출된 데이터 추가\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>str_Declaration</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           comment  label\n",
       "0  str_Declaration     -1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_declaration = {\n",
    "    'comment' : [\"str_Declaration\"],\n",
    "    'label':[-1]\n",
    "}\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data_declaration)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 개수를 모두 2000 개로 지정 각 \n",
    "# 라벨은 혐오:0, 여성비하: 1, 일베: 2로 지정됨\n",
    "data = random_labeling(data, hate_data, 0, 2000)\n",
    "data = random_labeling(data, genderbias_data, 1, 1200)\n",
    "data = random_labeling(data, ilbe_data, 2, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 첫번째 행 제거\n",
    "data = data.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 랜덤하게 섞기 \n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>무개념 개티즌들이 망친 평점 다시올라가길.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'일본이 모든 음식의 기원한 곳이라고 한거 너잔아 씨발년아'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>윤여정의 새로운 발견,,,코를 징끗하며 ,, 타고난 연기의 화신</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>트럼프 존나젊어보이네 나홀로집에2 나오던때냐</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>겁나 재밌어요 짱짱짱ㅋㅋㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>이명박이 걸그룹하는나라가 됐구나 만족하니 페미들아?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>삽자루가 뭔 우파여 또라이인가</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>댓글에서 여성 비율이 유독 높은게 연예인 관련 기사인데...수준낮고 남 저주하는 글...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>아니 수천억 가져야 버는돈을 박가린 존못 bj 가 비슷하게범 ㅋㅋ 20프로 슈수료 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>오늘 여섯살 아들과 보고 왔어요. 아들 첫 극장 관람이라 너무도 재밌게 보았다고 하...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label\n",
       "0                            무개념 개티즌들이 망친 평점 다시올라가길.      0\n",
       "1                  '일본이 모든 음식의 기원한 곳이라고 한거 너잔아 씨발년아'      2\n",
       "2                윤여정의 새로운 발견,,,코를 징끗하며 ,, 타고난 연기의 화신      0\n",
       "3                           트럼프 존나젊어보이네 나홀로집에2 나오던때냐      2\n",
       "4                                    겁나 재밌어요 짱짱짱ㅋㅋㅋㅋ      0\n",
       "5                       이명박이 걸그룹하는나라가 됐구나 만족하니 페미들아?      1\n",
       "6                                   삽자루가 뭔 우파여 또라이인가      2\n",
       "7  댓글에서 여성 비율이 유독 높은게 연예인 관련 기사인데...수준낮고 남 저주하는 글...      1\n",
       "8  아니 수천억 가져야 버는돈을 박가린 존못 bj 가 비슷하게범 ㅋㅋ 20프로 슈수료 ...      2\n",
       "9  오늘 여섯살 아들과 보고 왔어요. 아들 첫 극장 관람이라 너무도 재밌게 보았다고 하...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복 및 null 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_overlap(data):\n",
    "    exist_overlap = len(data)  # 데이터 전체 개수\n",
    "    no_overlap = data['comment'].nunique()  # 중복 제거된 개수\n",
    "    if exist_overlap != no_overlap:\n",
    "        data.drop_duplicates(subset=['comment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_overlap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null 값 확인\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x_data, tokenizer):\n",
    "    tokenizer.fit_on_texts(x_data) # 데이터의 각 행별로 토큰화 수행\n",
    "    return tokenizer.texts_to_sequences(x_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data['comment']\n",
    "y_data = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "sequences = tokenize(x_data, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 희귀단어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rareword(tokenizer, threshold):\n",
    "    word_to_index = tokenizer.word_index \n",
    "    total_cnt = len(word_to_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등장 빈도가 1번 이하인 희귀 단어의 수: 23305\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 83.07489395073611\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 48.546015081448154\n"
     ]
    }
   ],
   "source": [
    "# 희귀 단어 확인\n",
    "detect_rareword(tokenizer, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터, 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 길이\n",
    "def max_length(X_data):\n",
    "    return max(len(l) for l in X_data)\n",
    "\n",
    "# 훈련 학습 데이터 개수\n",
    "def num_dataset(raio, X_data):\n",
    "    num_train = int(len(X_data)*0.8)\n",
    "    num_test = int(len(X_data) - num_train)\n",
    "    return num_train, num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이 계산\n",
    "X_data = sequences\n",
    "maxlen = max_length(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 최대 길이 : 194\n",
      "문장 평균 길이 : 9.251494\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('문장 최대 길이 : %d' % max(len(l) for l in X_data))\n",
    "print('문장 평균 길이 : %f' % (sum(map(len, X_data))/len(X_data)))\n",
    "plt.hist([len(s) for s in X_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터, 학습 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 학습 데이터 개수 비율 지정\n",
    "numtrain, numtest = num_dataset(0.8, X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 길이로 맞추기\n",
    "X_data = pad_sequences(X_data, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import pandas as pd\n",
    "import tensorflow.keras.metrics \n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision_v = precision(y_true, y_pred)\n",
    "    recall_v = recall(y_true, y_pred)\n",
    "    return 2*((precision_v*recall_v)/(precision_v+recall_v+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 32/325 [=>............................] - ETA: 6:21 - loss: 6.2008 - accuracy: 0.3221 - f1: 0.1096 - precision: 4684899.8828 - recall: 0.0548"
     ]
    }
   ],
   "source": [
    "# size = 1000000\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(size , 64, input_length = maxlen)) #워드 임베딩\n",
    "# model.add(Dropout(0.5)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "# model.add(Conv1D(64, 3, padding='valid', activation='relu')) #hidden layer 추가\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(Dropout(0.5)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "# num_of_class = 3 #클래스는 우선 4개로 분류함\n",
    "# model.add(Dense(num_of_class, activation='linear'))\n",
    "# ##model.add(Dense(num_of_class, activation='softmax')) #마지막 레이어는 softmax로 출력하게 함\n",
    "# model.summary()\n",
    "\n",
    "size = 1000000\n",
    "\n",
    "kfold = KFold(n_splits= 5, shuffle = True)\n",
    "\n",
    "for train, test in kfold.split(X_data, Y_data):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(size , 64, input_length = maxlen)) #워드 임베딩\n",
    "    model.add(Dropout(0.5)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "    model.add(Conv1D(64, 3, padding='valid', activation='relu')) #hidden layer 추가\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.5)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "    num_of_class = 3 #클래스는 우선 4개로 분류함\n",
    "    model.add(Dense(num_of_class, activation='linear'))\n",
    "    ##model.add(Dense(num_of_class, activation='softmax')) #마지막 레이어는 softmax로 출력하게 함\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"accuracy\",f1,precision, recall])\n",
    "    es = EarlyStopping(monitor='loss', mode='min' , min_delta=0)\n",
    "    check_point = ModelCheckpoint('best_model.h5', monitor='loss', mode='min', save_best_only=True)\n",
    "    \n",
    "    hist = model.fit(X_data, y_data, batch_size = 16, epochs=10, callbacks=[es, check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_result = model.predict(X_test, batch_size = 16)\n",
    "X_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_result = []\n",
    "for a,b,c in X_result:\n",
    "    numbers = [a,b,c]\n",
    "    class_result.append(numbers.index(max(numbers)))\n",
    "    \n",
    "tf_result = (y_test == class_result)\n",
    "\n",
    "for_open_max_0 = []; \n",
    "for_open_max_1 = [];\n",
    "for_open_max_2 = [];\n",
    "\n",
    "for i in range(len(class_result)):\n",
    "    if(tf_result[i] == True):\n",
    "        if(class_result[i] == 0):\n",
    "            for_open_max_0.append(X_result[i])\n",
    "        if(class_result[i] == 1):\n",
    "            for_open_max_1.append(X_result[i])\n",
    "        if(class_result[i] == 2):\n",
    "            for_open_max_2.append(X_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평균 Logit Vector 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vector(for_open_max, class_result):\n",
    "    a1=0\n",
    "    a2=0\n",
    "    a3=0\n",
    "    for i in for_open_max:\n",
    "        a1 += i[0]\n",
    "        a2 += i[1]\n",
    "        a3 += i[2]\n",
    "    length = len(class_result)\n",
    "    average = [a1/length, a2/length, a3/length]\n",
    "    return average\n",
    "\n",
    "average_0 = average_vector(for_open_max_0, class_result) #평균 Logit Vector - Class 0\n",
    "average_1 = average_vector(for_open_max_1, class_result) #평균 Logit Vector - Class 1\n",
    "average_2 = average_vector(for_open_max_2, class_result) #평균 Logit Vector - Class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(for_open_max, average):\n",
    "    dist = []\n",
    "    for i in for_open_max:\n",
    "        m = i - average\n",
    "        distance = (m[0]**2) + (m[1]**2) + (m[2]**2)\n",
    "        dist.append(distance)\n",
    "    return dist\n",
    "\n",
    "dist0 = distance(for_open_max_0, average_0)\n",
    "dist1 = distance(for_open_max_1, average_1)\n",
    "dist2 = distance(for_open_max_2, average_2)\n",
    "\n",
    "dist0.sort(reverse =True)\n",
    "dist1.sort(reverse =True)\n",
    "dist2.sort(reverse =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance 상위 20개 추출\n",
    "maxdist0=[]\n",
    "maxdist1=[]\n",
    "maxdist2=[]\n",
    "for i in range(0,20):\n",
    "    maxdist0.append(dist0[i])\n",
    "for j in range(0,20):\n",
    "    maxdist1.append(dist1[j])\n",
    "for k in range(0,20):\n",
    "    maxdist2.append(dist2[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#극단 분포 도구\n",
    "import scipy.stats as s\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#def weib(x,n,a):\n",
    "#    return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)\n",
    "def weib(x,n,a):\n",
    "    return 1-np.exp[-(x / n)**a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 라벨 Distance 추출 Weibull 극단 분포 CDF\n",
    "(loc, scale) = s.exponweib.fit_loc_scale(maxdist0, 1, 1)\n",
    "print(loc, scale)\n",
    "\n",
    "plt.plot(maxdist0, s.exponweib.cdf(maxdist0, *s.exponweib.fit(maxdist0, 1, 1, scale=2, loc=0)))\n",
    "_ = plt.hist(maxdist0, bins=np.linspace(0, 16, 33), alpha=0.5);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 라벨 Distance 추출 Weibull 극단 분포 CDF\n",
    "(loc, scale) = s.exponweib.fit_loc_scale(maxdist1, 1, 1)\n",
    "print(loc, scale)\n",
    "\n",
    "plt.plot(maxdist1, s.exponweib.cdf(maxdist1, *s.exponweib.fit(maxdist1, 1, 1, scale=2, loc=0)))\n",
    "_ = plt.hist(maxdist1, bins=np.linspace(0, 16, 33), alpha=0.5);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 라벨 Distance 추출 Weibull 극단 분포 CDF\n",
    "(loc, scale) = s.exponweib.fit_loc_scale(maxdist2, 1, 1)\n",
    "print(loc, scale)\n",
    "\n",
    "plt.plot(maxdist2, s.exponweib.cdf(maxdist2, *s.exponweib.fit(maxdist2, 1, 1, scale=2, loc=0)))\n",
    "_ = plt.hist(maxdist2, bins=np.linspace(0, 16, 33), alpha=0.5);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Layer 통과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(num_of_class + 1, activation = 'softmax'))\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_result, y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.predict(X_result, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 학습 과정 표시\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(model.predict(X_test, batch_size=16),columns=['0', '1', '2'])\n",
    "result[\"Test Label\"] = y_test\n",
    "result[\"Classification Result\"] = class_result\n",
    "result[\"Final Result\"] = (y_test == class_result)\n",
    "\n",
    "result.to_csv(\"test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##모델을 .json 파일 형식으로 save하여 저장\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"model_weight.h5\")\n",
    "model.save('full_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##모델 조정이 끝나면, Model을 사용 하여 OpenMax에 필요한 자료를 선정하여 OpenMax로 구현할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
