{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d1e8cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import_ipynb in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "!pip install import_ipynb\n",
    "import import_ipynb\n",
    "import model_test_for_openmax_add_CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02837354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 나는 진하빈입니다\n"
     ]
    }
   ],
   "source": [
    "input_data = input()         # 아직 입력부를 구현하지 않아 임시로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21fd36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x_data, tokenizer):\n",
    "    tokenizer.fit_on_texts(x_data) # 데이터의 각 행별로 토큰화 수행\n",
    "    return tokenizer.texts_to_sequences(x_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ca23929",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = input_data\n",
    "y_data = 0    # 임시 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d227dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "sequences = tokenize(x_data, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa16f3",
   "metadata": {},
   "source": [
    "## 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b24325db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras.models in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: keras in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras.models) (2.4.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras.models) (8.2.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras.models) (3.0.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras.models) (4.5.2.54)\n",
      "Requirement already satisfied: pathlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras.models) (1.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras.models) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras->keras.models) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras->keras.models) (1.6.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras->keras.models) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from h5py->keras->keras.models) (1.15.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (4.59.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (2.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (0.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (20.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (0.5.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (1.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (2.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (2.25.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (1.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (2.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (52.0.0.post20210125)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy->keras.models) (8.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy->keras.models) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy->keras.models) (3.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->keras.models) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->keras.models) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->keras.models) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->keras.models) (2020.12.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy->keras.models) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy->keras.models) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras.models\n",
    "from keras.models import model_from_json\n",
    "json_file = open(\"model.json\", \"r\")\n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc59e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_weights(\"model_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66602d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True),metrics= [\"accuracy\"])\n",
    "#es = EarlyStopping(monitor='loss', mode='min' , min_delta=0)\n",
    "#check_point = ModelCheckpoint('apply_model.h5', monitor='loss', mode='min', save_best_only=True)\n",
    "loaded_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11f7f1d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-eee83c9cab80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m         \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1354\u001b[1;33m         data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1355\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         sample_weights, sample_weight_modes)\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m     self._internal_adapter = TensorLikeDataAdapter(\n\u001b[0m\u001b[0;32m    644\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "X_result = loaded_model.evaluate(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a2472",
   "metadata": {},
   "source": [
    "## logit Vector, Distance 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40071700",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-aad47c78ad91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclass_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclass_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtf_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mclass_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "class_result = 0\n",
    "class_result = X_result.index(max(X_result))\n",
    "\n",
    "tf_result = (y_test == class_result)\n",
    "\n",
    "if(tf_result == True):\n",
    "    if(class_result == 0):\n",
    "        for_open_max_0 = X_result\n",
    "    if(class_result == 1):\n",
    "        for_open_max_1 = X_result\n",
    "    if(class_result == 2):\n",
    "        for_open_max_2 = X_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b304eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_average_0 = average_vector(for_open_max_0, class_result) #평균 Logit Vector - Class 0\n",
    "input_average_1 = average_vector(for_open_max_1, class_result) #평균 Logit Vector - Class 1\n",
    "input_average_2 = average_vector(for_open_max_2, class_result) #평균 Logit Vector - Class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d641b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist0 = distance(for_open_max_0, input_average_0)\n",
    "dist1 = distance(for_open_max_1, input_average_1)\n",
    "dist2 = distance(for_open_max_2, input_average_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116d3c2",
   "metadata": {},
   "source": [
    "## CDF 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculCDF(dist):\n",
    "    CDF = []\n",
    "    for i in dist:\n",
    "        CDF.append(s.exponweib.cdf(i, *s.exponweib.fit(i, 1, 1, scale=2, loc=0)))     \n",
    "        return CDF\n",
    "CDF0 = calculCDF(dist0)\n",
    "CDF1 = calculCDF(dist1)\n",
    "CDF2 = calculCDF(dist2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a637b12",
   "metadata": {},
   "source": [
    "## Logit Vetcr 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_logit = []\n",
    "i = 0\n",
    "\n",
    "logit0 = X_result[0]-(X_result[0]*CDF0[i])\n",
    "logit1 = X_result[1]-(X_result[1]*CDF1[i])\n",
    "logit2 = X_result[2]-(X_result[2]*CDF2[i])\n",
    "unkn_logit = CDF0[i]*X_result[0] + CDF1[i]*X_result[1] + CDF2[i]*X_result[2]    # unknown class의 logit vector\n",
    "updated_logit.append([unkn_logit, logit0, logit1, logit2])     \n",
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update 된 logit veoctor로 softmax layer 통과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d49f4",
   "metadata": {},
   "source": [
    "## Softmax Layer 통과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed738992",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(Dense(num_of_class + 1, activation = 'softmax'))\n",
    "optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"accuracy\",f1,precision, recall])\n",
    "check_point = ModelCheckpoint('new_best_model.h5', monitor='loss', mode='min', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(x_data, y_data, batch_size = 16, epochs=10, callbacks=[es, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02416cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(X_result, batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209dfe49",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"Classification Result\"] = class_result\n",
    "result[\"Final Result\"] = (y_test == class_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c32a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(x_data, y_data)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc68ce",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a44c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##모델을 .json 파일 형식으로 save하여 저장\n",
    "model_json = model.to_json()\n",
    "with open(\"new_model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"new_model_weight.h5\")\n",
    "model.save('new_full_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be0d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
