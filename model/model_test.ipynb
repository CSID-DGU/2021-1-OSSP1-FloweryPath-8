{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_data = pd.read_csv(\"hate_speech_binary_dataset.csv\", delimiter=\",\") # 혐오 문장\n",
    "genderbias_data = pd.read_csv('genderbias.csv', sep=',')  # 여성 비하 문장\n",
    "ilbe_data = pd.read_csv('badword.csv',encoding='CP949') # 일베 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혐오 문장 처리\n",
    "hate_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "hate_data = hate_data.astype({'comment': 'str'})\n",
    "hate_data = hate_data[hate_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여성 비하 문장 처리\n",
    "del genderbias_data['bias']    #해당 데이터셋의 필요없는 열 제거\n",
    "del genderbias_data['hate']    #해당 데이터셋의 필요없는 열 제거\n",
    "genderbias_data['contain_gender_bias'] = genderbias_data['contain_gender_bias'].replace([False, True],[0,1])  # 구분하기 쉽게 기존의 표기를 0,1로 변경\n",
    "# genderbias_data = genderbias_data[['contain_gender_bias', 'comments']]    #구분하기 쉽게 열의 순서를 변경\n",
    "\n",
    "genderbias_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "genderbias_data = genderbias_data[genderbias_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일베 문장 처리\n",
    "ilbe_data = ilbe_data[['v2', 'v1']]    #구분하기 쉽게 열의 순서를 변경\n",
    "ilbe_data.columns = ['comment', 'label'] # 컬럼 명 변경\n",
    "ilbe_data = ilbe_data[ilbe_data['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_data : 100000\n",
      "genderbias_data : 1232\n",
      "ilbe_data : 2044\n"
     ]
    }
   ],
   "source": [
    "# 데이터 개수\n",
    "print(\"hate_data : %d\" % len(hate_data))\n",
    "print(\"genderbias_data : %d\" % len(genderbias_data))\n",
    "print(\"ilbe_data : %d\" % len(ilbe_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라벨링 및 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 렌덤하게 문장 추출 후 라벨링 거치는 함수\n",
    "def random_labeling(data, classified_data, label_num, str_num):  # label_num : 라벨링 시킬 값, str_num 추출할 문장 개수\n",
    "    random_data = classified_data.sample(n=str_num) # str_num 개의 행(문장) 랜덤 추출\n",
    "    random_data.loc[random_data.label == 1, 'label'] = label_num # label_num으로 값 변경\n",
    "    data = data.append(random_data)  # data 에 랜덤 추출된 데이터 추가\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>str_Declaration</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           comment  label\n",
       "0  str_Declaration     -1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_declaration = {\n",
    "    'comment' : [\"str_Declaration\"],\n",
    "    'label':[-1]\n",
    "}\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data_declaration)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 개수를 모두 2000 개로 지정 각 \n",
    "# 라벨은 혐오:0, 여성비하: 1, 일베: 2로 지정됨\n",
    "data = random_labeling(data, hate_data, 0, 2000)\n",
    "data = random_labeling(data, genderbias_data, 1, 1200)\n",
    "data = random_labeling(data, ilbe_data, 2, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 첫번째 행 제거\n",
    "data = data.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 랜덤하게 섞기 \n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그딴거 필요없고 백마나 스시녀랑 결혼하면 승자되는거 모르노?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>개씹뜬금없네 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일베에서 틀딱거리는 새끼들 = 전라도 대깨문 평균나이 50대이상지들이 노인인 줄 모...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>대구.경북.포항은 일베틀딱병신들만 있어서 당선됨</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>쓸쓸한 영화. 참 잘 만들었다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>저딴 생각을 하지?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>여자 내스탈인데 뺏고싶네</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>La Merr~~~~</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>우주의 기운이나 받아라 멍충아</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>세계챔피언. 스트리트 파이터 되다!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label\n",
       "0                  그딴거 필요없고 백마나 스시녀랑 결혼하면 승자되는거 모르노?      2\n",
       "1                                  개씹뜬금없네 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ      2\n",
       "2  일베에서 틀딱거리는 새끼들 = 전라도 대깨문 평균나이 50대이상지들이 노인인 줄 모...      2\n",
       "3                         대구.경북.포항은 일베틀딱병신들만 있어서 당선됨      2\n",
       "4                                  쓸쓸한 영화. 참 잘 만들었다.      0\n",
       "5                                         저딴 생각을 하지?      2\n",
       "6                                      여자 내스탈인데 뺏고싶네      1\n",
       "7                                        La Merr~~~~      0\n",
       "8                                   우주의 기운이나 받아라 멍충아      2\n",
       "9                                세계챔피언. 스트리트 파이터 되다!      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복 및 null 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_overlap(data):\n",
    "    exist_overlap = len(data)  # 데이터 전체 개수\n",
    "    no_overlap = data['comment'].nunique()  # 중복 제거된 개수\n",
    "    if exist_overlap != no_overlap:\n",
    "        data.drop_duplicates(subset=['comment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_overlap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null 값 확인\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x_data, tokenizer):\n",
    "    tokenizer.fit_on_texts(x_data) # 데이터의 각 행별로 토큰화 수행\n",
    "    return tokenizer.texts_to_sequences(x_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data['comment']\n",
    "y_data = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "sequences = tokenize(x_data, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 희귀단어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rareword(tokenizer, threshold):\n",
    "    word_to_index = tokenizer.word_index \n",
    "    total_cnt = len(word_to_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등장 빈도가 1번 이하인 희귀 단어의 수: 30946\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 81.6043457623543\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 42.297336085179666\n"
     ]
    }
   ],
   "source": [
    "# 희귀 단어 확인\n",
    "detect_rareword(tokenizer, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터, 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 길이\n",
    "def max_length(X_data):\n",
    "    return max(len(l) for l in X_data)\n",
    "\n",
    "# 훈련 학습 데이터 개수\n",
    "def num_dataset(raio, X_data):\n",
    "    num_train = int(len(X_data)*0.8)\n",
    "    num_test = int(len(X_data) - num_train)\n",
    "    return num_train, num_test\n",
    "\n",
    "# 훈련 및 학습 데이터 분리\n",
    "def config_dataset(num_train, data):\n",
    "    X_test = data[num_train:] #X_data 데이터 중에서 뒤의 개의 데이터만 저장\n",
    "    y_test = np.array(y_data[num_train:]) #y_data 데이터 중에서 뒤의 개의 데이터만 저장\n",
    "    X_train = data[:num_train] #X_data 데이터 중에서 앞의 n_of_train개의 데이터만 저장\n",
    "    y_train = np.array(y_data[:num_train]) #y_data 데이터 중에서 앞의 n_of_train개의 데이터만 저장\n",
    "    \n",
    "    return X_test, y_test, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이 계산\n",
    "X_data = sequences\n",
    "maxlen = max_length(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 최대 길이 : 194\n",
      "문장 평균 길이 : 8.809512\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('문장 최대 길이 : %d' % max(len(l) for l in X_data))\n",
    "print('문장 평균 길이 : %f' % (sum(map(len, X_data))/len(X_data)))\n",
    "plt.hist([len(s) for s in X_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터, 학습 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 학습 데이터 개수 비율 지정\n",
    "numtrain, numtest = num_dataset(0.8, X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 길이로 맞추기\n",
    "data = pad_sequences(X_data, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, X_train, y_train = config_dataset(numtrain, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   993,  6979,  6980],\n",
       "       [    0,     0,     0, ...,     0,  6981,   511],\n",
       "       [    0,     0,     0, ...,   137,    15,  3616],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   450, 32215,  3518],\n",
       "       [    0,     0,     0, ...,  4526, 32217,  1970],\n",
       "       [    0,     0,     0, ...,     0,   439,  1978]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import tensorflow.keras.metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 194, 64)           64000000  \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 194, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 192, 64)           12352     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 64,016,707\n",
      "Trainable params: 64,016,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "size = 1000000\n",
    "model = Sequential()\n",
    "model.add(Embedding(size , 64, input_length = maxlen)) #워드 임베딩\n",
    "model.add(Dropout(0.6)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "model.add(Conv1D(64, 3, padding='valid', activation='relu')) #hidden layer 추가\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.6)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.6)) #과적합 방지를 위해 일부 Drop, 기본 50% 정도를 Drop하도록 설정함.\n",
    "num_of_class = 3 #클래스는 우선 4개로 분류함\n",
    "model.add(Dense(num_of_class, activation='softmax')) #마지막 레이어는 softmax로 출력하게 함\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics= [\"accuracy\"])\n",
    "es = EarlyStopping(monitor='loss', mode='min' , min_delta=0)\n",
    "check_point = ModelCheckpoint('best_model.h5', monitor='loss', mode='min', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "416/416 [==============================] - 153s 369ms/step - loss: 0.9919 - accuracy: 0.5625\n",
      "Epoch 2/10\n",
      "416/416 [==============================] - 155s 372ms/step - loss: 0.8766 - accuracy: 0.5871\n",
      "Epoch 3/10\n",
      "416/416 [==============================] - 155s 372ms/step - loss: 0.6094 - accuracy: 0.7279\n",
      "Epoch 4/10\n",
      "416/416 [==============================] - 154s 370ms/step - loss: 0.4291 - accuracy: 0.8022\n",
      "Epoch 5/10\n",
      "416/416 [==============================] - 156s 375ms/step - loss: 0.3389 - accuracy: 0.8435\n",
      "Epoch 6/10\n",
      "416/416 [==============================] - 156s 375ms/step - loss: 0.2429 - accuracy: 0.9053\n",
      "Epoch 7/10\n",
      "416/416 [==============================] - 156s 375ms/step - loss: 0.1415 - accuracy: 0.9574\n",
      "Epoch 8/10\n",
      "416/416 [==============================] - 157s 377ms/step - loss: 0.0987 - accuracy: 0.9752\n",
      "Epoch 9/10\n",
      "416/416 [==============================] - 157s 378ms/step - loss: 0.0567 - accuracy: 0.9859\n",
      "Epoch 10/10\n",
      "416/416 [==============================] - 157s 377ms/step - loss: 0.0412 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size = 16, epochs=10, callbacks=[es, check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 학습 과정 표시\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='value loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.2613990e-03, 1.0295760e-01, 8.9078104e-01],\n",
       "       [5.3515267e-01, 1.3215740e-01, 3.3269000e-01],\n",
       "       [8.2986277e-01, 1.1794212e-01, 5.2195210e-02],\n",
       "       ...,\n",
       "       [9.2026077e-02, 8.5127479e-01, 5.6699093e-02],\n",
       "       [9.9999976e-01, 2.4796475e-07, 2.5235852e-10],\n",
       "       [7.9946297e-01, 7.0088916e-02, 1.3044821e-01]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predict Result\")\n",
    "model.predict(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.8085\n",
      "테스트 정확도: 0.8085\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "##모델을 .json 파일 형식으로 save하여 저장\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"model_weight.h5\")\n",
    "model.save('full_model.h5')\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##모델 조정이 아직 끝나지 않았습니다. 테스트 정확도를 더 늘리기 위해서 모델을 추가로 수정할 예정입니다,\n",
    "##모델 조정이 끝나면, Model을 사용하여 OpenMax에 필요한 자료를 선정하여 OpenMax로 구현할 예정입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
