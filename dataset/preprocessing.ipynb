{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_data = pd.read_csv(\"./hate_speech_binary_dataset.csv\", delimiter=\",\") # 혐오 문장\n",
    "genderbias_data = pd.read_csv('./genderbias.csv', sep=',')  # 여성 비하 문장\n",
    "ilbe_data = pd.read_csv('./badword.csv',encoding='CP949') # 일베 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혐오 문장 처리\n",
    "hate_data.columns = ['comment', 'label_hate'] # 컬럼 명 변경\n",
    "hate_data = hate_data.astype({'comment': 'str'})\n",
    "hate_data = hate_data[hate_data['label_hate']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여성 비하 문장 처리\n",
    "del genderbias_data['bias']    #해당 데이터셋의 필요없는 열 제거\n",
    "del genderbias_data['hate']    #해당 데이터셋의 필요없는 열 제거\n",
    "genderbias_data['contain_gender_bias'] = genderbias_data['contain_gender_bias'].replace([False, True],[0,1])  # 구분하기 쉽게 기존의 표기를 0,1로 변경\n",
    "# genderbias_data = genderbias_data[['contain_gender_bias', 'comments']]    #구분하기 쉽게 열의 순서를 변경\n",
    "\n",
    "genderbias_data.columns = ['comment', 'label_genderbias'] # 컬럼 명 변경\n",
    "genderbias_data = genderbias_data[genderbias_data['label_genderbias']==1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일베 문장 처리\n",
    "ilbe_data = ilbe_data[['v2', 'v1']]    #구분하기 쉽게 열의 순서를 변경\n",
    "ilbe_data.columns = ['comment', 'label_ilbe'] # 컬럼 명 변경\n",
    "ilbe_data = ilbe_data[ilbe_data['label_ilbe']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label_ilbe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건 ㅇㅂ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고 ㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>731부대의 후예라 그런지 가학적인 아이디어는 세계최고임 이래서 애교만 떨어도 돈 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>재앙이한건햇노</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5812</th>\n",
       "      <td>진짜 저 개성없는 머리는 왜 하는거냐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813</th>\n",
       "      <td>오나1홀도 애1무 잘해주면 물 나온다 함 해보라ㅏ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5814</th>\n",
       "      <td>좀있으면 100억도 나오겠네 시발 ㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>세금 내놓으라고 데모질 중 ㅋㅋ간첩  도둑놈 새끼들이 대통령 해처먹으니까  나도 같...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>우리나라교회는 악마들이모여 주뎅이 처벌리고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  label_ilbe\n",
       "0                                             좌배 까는건 ㅇㅂ           1\n",
       "2           개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아           1\n",
       "4                                    애새끼가 초딩도 아니고 ㅋㅋㅋㅋ            1\n",
       "5     731부대의 후예라 그런지 가학적인 아이디어는 세계최고임 이래서 애교만 떨어도 돈 ...           1\n",
       "6                                               재앙이한건햇노           1\n",
       "...                                                 ...         ...\n",
       "5812                               진짜 저 개성없는 머리는 왜 하는거냐           1\n",
       "5813                        오나1홀도 애1무 잘해주면 물 나온다 함 해보라ㅏ           1\n",
       "5814                          좀있으면 100억도 나오겠네 시발 ㅋㅋㅋㅋㅋㅋ           1\n",
       "5819  세금 내놓으라고 데모질 중 ㅋㅋ간첩  도둑놈 새끼들이 대통령 해처먹으니까  나도 같...           1\n",
       "5822                           우리나라교회는 악마들이모여 주뎅이 처벌리고            1\n",
       "\n",
       "[2044 rows x 2 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilbe_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복 및 null 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_overlap(data):\n",
    "    exist_overlap = len(data)  # 데이터 전체 개수\n",
    "    no_overlap = data['comment'].nunique()  # 중복 제거된 개수\n",
    "    if exist_overlap != no_overlap:\n",
    "        data.drop_duplicates(subset=['comment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_overlap(hate_data)\n",
    "detect_overlap(genderbias_data)\n",
    "detect_overlap(ilbe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null 값 확인\n",
    "genderbias_data.isnull().values.any()\n",
    "hate_data.isnull().values.any()\n",
    "ilbe_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x_data, tokenizer):\n",
    "    tokenizer.fit_on_texts(x_data) # 데이터의 각 행별로 토큰화 수행\n",
    "    return tokenizer.texts_to_sequences(x_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hatedata = hate_data['comment']\n",
    "y_hatedata = hate_data['label_hate']\n",
    "\n",
    "x_genderbiasdata = genderbias_data['comment']\n",
    "y_genderbiasdata = genderbias_data['label_genderbias']\n",
    "\n",
    "x_ilbedata = ilbe_data['comment']\n",
    "y_ilbedata = ilbe_data['label_ilbe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_hate = Tokenizer()\n",
    "sequences_hate = tokenize(x_hatedata, tokenizer_hate)\n",
    "\n",
    "tokenizer_genderbias = Tokenizer()\n",
    "sequences_genderbias = tokenize(x_genderbiasdata, tokenizer_genderbias)\n",
    "\n",
    "tokenizer_ilbe = Tokenizer()\n",
    "sequences_ilbe = tokenize(x_ilbedata, tokenizer_ilbe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 희귀단어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rareword(tokenizer, treshold):\n",
    "    word_to_index = tokenizer.word_index \n",
    "    total_cnt = len(word_to_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print(\"단어 집합(vocabulary)에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등장 빈도가 1번 이하인 희귀 단어의 수: 149985\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 75.64112262652243\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 19.47348808947275\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 7544\n",
      "단어 집합(vocabulary)에서 희귀 단어의 비율: 85.92255125284738\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 59.08521303258145\n"
     ]
    }
   ],
   "source": [
    "# 희귀 단어 확인\n",
    "detect_rareword(tokenizer_hate, 2)\n",
    "detect_rareword(tokenizer_genderbias, 2)\n",
    "detect_rareword(tokenizer_ilbe, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터, 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 길이\n",
    "def max_length(X_data):\n",
    "    return max(len(l) for l in X_data)\n",
    "\n",
    "# 훈련 학습 데이터 개수\n",
    "def num_dataset(raio, X_data):\n",
    "    num_train = int(len(X_data)*0.8)\n",
    "    num_test = int(len(X_data) - num_train)\n",
    "    return num_train, num_test\n",
    "\n",
    "# 훈련 및 학습 데이터 분리\n",
    "def config_dataset(num_train, data):\n",
    "    X_test = data[num_train:] #X_data 데이터 중에서 뒤의 개의 데이터만 저장\n",
    "    y_test = np.array(y_data[num_train:]) #y_data 데이터 중에서 뒤의 개의 데이터만 저장\n",
    "    X_train = data[:num_train] #X_data 데이터 중에서 앞의 n_of_train개의 데이터만 저장\n",
    "    y_train = np.array(y_data[:num_train]) #y_data 데이터 중에서 앞의 n_of_train개의 데이터만 저장\n",
    "    \n",
    "    return X_test, y_test, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이 계산\n",
    "X_hatedata = sequences_hate\n",
    "maxlen_hate = max_length(X_hatedata)\n",
    "\n",
    "X_genderbiasdata = sequences_genderbias\n",
    "maxlen_genderbias = max_length(X_genderbiasdata)\n",
    "\n",
    "X_ilbedata = sequences_ilbe\n",
    "maxlen_ilbe = max_length(X_ilbedata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 학습 데이터 개수 비율 지정\n",
    "\n",
    "numtrain_hate, numtest_hate = num_dataset(0.8, X_hatedata)\n",
    "numtrain_genderbias, numtest_genderbias = num_dataset(0.8, X_genderbiasdata)\n",
    "numtrain_ilbe, numtest_ilbe = num_dataset(0.8, X_ilbedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 길이로 맞추기\n",
    "hatedata = pad_sequences(X_hatedata, maxlen = maxlen_hate)\n",
    "genderbiasdata = pad_sequences(X_genderbiasdata, maxlen = maxlen_genderbias)\n",
    "ilbedata = pad_sequences(X_ilbedata, maxlen = maxlen_ilbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hatetest, y_hatetest, X_hatetrain, y_hatetrain = config_dataset(numtrain_hate, hatedata)\n",
    "X_genderbiastest, y_genderbiastest, X_genderbiastrain, y_genderbiastrain = config_dataset(numtrain_genderbias, genderbiasdata)\n",
    "X_ilbetest, y_ilbetest, X_ilbetrain, y_ilbetrain = config_dataset(numtrain_ilbe, ilbedata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
